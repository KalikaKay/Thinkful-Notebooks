{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before answering this question, see where you are in the data-processing workflow:\n",
    "\n",
    "![Feature Engineering](assets/feature_engineering.png)\n",
    "\n",
    "As the diagram above shows, with this checkpoint, you'll start to explore how to convert text data into numerical form. This is the feature-engineering step that you need to do before feeding your data into any machine-learning algorithm. Converting text into numerical form is often called *language modeling* in NLP jargon, and it's one of the most active research areas in NLP. This process is called language modeling because of semantics; a good numerical representation of the text should be able to capture the meaning of the words and their relationships between each other. You'll learn about semantics in the next checkpoint. For now, you'll just focus on a simple way to represent words in numerical form.\n",
    "\n",
    "To accommodate the feature-generation techniques that you'll learn here and to see how they perform on a machine-learning task, you'll feed your new numerical features into some machine-learning algorithms. You'll also make some classifications to demonstrate the pros and cons of your feature-engineering methods. Hence, your first hands-on NLP application in this module will be *text classification*. \n",
    "\n",
    "Continue on to get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words\n",
    "\n",
    "The first feature-generation approach that you'll learn about here is called *bag-of-words* (BoW). BoW is quite simple: your goal is to create a feature matrix such that the rows are observations, and each column is a unique word in your vocabulary. You fill in this matrix by counting how many times each word appears in each observation. You then use those counts as features. \n",
    "\n",
    "As mentioned, BoW is simple and very easy to implement using libraries like scikit-learn. In the jargon of scikit-learn, generating BoW features is called `CountVectorizer`, as you'll see shortly. However, before moving on to implement the BoW approach, you'll need to do some data cleaning. \n",
    "\n",
    "Begin by importing the libraries that you'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import en_core_web_sm as spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a helper function called `text_cleaner` for cleaning the text. Specifically, remove some punctuation marks and numbers from the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation that spaCy doesn't\n",
    "    # recognize: the double dash '--'. Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load Jane Austen's *Persuasion* and Lewis Carroll's *Alice's Adventures in Wonderland* from NLTK's Gutenberg module. In this checkpoint, you'll be working on these two texts, and your ultimate goal will be to distinguish the authors from their sentences. Hence, your unit of observation (your *documents*) will be the sentences of these novels.\n",
    "\n",
    "After you load the novels, do some data cleaning. First, remove the chapter indicators from the novels. Then apply the `text_cleaner` function from above to clean up some punctuation marks and the numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned texts are stored in two variables called `alice` and `persuasion`. Note that you haven't split the texts into sentences yet. You'll do that using spaCy. For that purpose, load spaCy's English module and use spaCy to parse both the `alice` and `persuasion` texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take some time.\n",
    "nlp = spacy.load()\n",
    "\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can split your texts into sentences now. This process is easy using spaCy. Because you've already parsed your documents with spaCy, you can now use spaCy's functionalities. In this case, spaCy will take care of deriving the sentences from the texts. What you need to do is to iterate over the parsed documents after calling the `.sents` attribute. With the following code, you can iterate using list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one DataFrame\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns = [\"text\", \"author\"])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "As a result, your dataset consists of two columns. The first column has the sentences, and the second column has the authors. Before jumping into BoW, you need to remove stop words and punctuation marks, and then convert your tokens to lemmas or stems. In this example, you'll lemmatize your tokens. Again, you'll make use of the attributes of the documents that spaCy parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of stop words and punctuation,\n",
    "# and lemmatize the tokens\n",
    "for i, sentence in enumerate(sentences[\"text\"]):\n",
    "    sentences.loc[i, \"text\"] = \" \".join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start converting the text in the first column of your dataset into a numerical form. As mentioned before, you'll use the BoW approach. For this purpose, use `CountVectorizer` from scikit-learn, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all! Now, check out your new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abode</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abominate</th>\n",
       "      <th>...</th>\n",
       "      <th>younker</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  abbreviation  abdication  abide  ability  able  abode  \\\n",
       "0    0     0             0           0      0        0     0      0   \n",
       "1    0     0             0           0      0        0     0      0   \n",
       "2    0     0             0           0      0        0     0      0   \n",
       "3    0     0             0           0      0        0     0      0   \n",
       "4    0     0             0           0      0        0     0      0   \n",
       "\n",
       "   abominable  abominate  ...  younker  youth  youthful  zeal  zealand  \\\n",
       "0           0          0  ...        0      0         0     0        0   \n",
       "1           0          0  ...        0      0         0     0        0   \n",
       "2           0          0  ...        0      0         0     0        0   \n",
       "3           0          0  ...        0      0         0     0        0   \n",
       "4           0          0  ...        0      0         0     0        0   \n",
       "\n",
       "   zealous  zealously  zigzag  \\\n",
       "0        0          0       0   \n",
       "1        0          0       0   \n",
       "2        0          0       0   \n",
       "3        0          0       0   \n",
       "4        0          0       0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 4873 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you now have a dataset that matches the format that you're used to in this program. It's in tabular form: observations are the rows and features are the columns. More importantly, you converted text into a numerical form, so you can apply machine-learning algorithms using these as input. This enables you to move to the modeling phase, as indicated below.\n",
    "\n",
    "![Modeling](assets/modeling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## BoW in action\n",
    "\n",
    "Now, give the bag-of-words features a whirl by trying some machine-learning algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9354838709677419\n",
      "\n",
      "Test set score: 0.8761651131824234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.86      0.97      0.91      1537\n",
      "     Carroll       0.91      0.67      0.78       716\n",
      "\n",
      "    accuracy                           0.88      2253\n",
      "   macro avg       0.89      0.82      0.85      2253\n",
      "weighted avg       0.88      0.88      0.87      2253\n",
      "\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9795797573246523\n",
      "\n",
      "Test set score: 0.8530847758544163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.88      0.91      0.89      1537\n",
      "     Carroll       0.79      0.74      0.76       716\n",
      "\n",
      "    accuracy                           0.85      2253\n",
      "   macro avg       0.83      0.82      0.83      2253\n",
      "weighted avg       0.85      0.85      0.85      2253\n",
      "\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8514353358981948\n",
      "\n",
      "Test set score: 0.8362183754993342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.82      0.97      0.89      1537\n",
      "     Carroll       0.91      0.54      0.68       716\n",
      "\n",
      "    accuracy                           0.84      2253\n",
      "   macro avg       0.86      0.76      0.78      2253\n",
      "weighted avg       0.85      0.84      0.82      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "print(classification_report(y_test, lr.predict(X_test)))\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "print(classification_report(y_test, rfc.predict(X_test)))\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))\n",
    "print(classification_report(y_test, gbc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "It looks like logistic regression and random forest overfit. Overfitting is a known problem when using the bag-of-words approach because it involves throwing a massive number of features at a model. Some of those features (in this case, word frequencies) will capture noise in the training set. Because overfitting is also a known problem with random forests, the divergence between training score and test score is expected. On the other hand, training and test scores from gradient boositng are close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams: words in context\n",
    "\n",
    "Consider the word `vain` in these two sentences:\n",
    "\n",
    "    “She labored in vain; the rock would not move.” \n",
    "\n",
    "    “She was so vain, her bathroom mirror was covered in lip prints.”\n",
    "\n",
    "In both sentences, `vain` is an adjective. In the first sentence, it signals a lack of success. In the second sentence, the same word means vanity. Since the two usages can't be distinguished by their part of speech, how can you tell them apart?\n",
    "\n",
    "*N-grams* incorporate context information by creating features made up of a series of consecutive words. The *n* refers to the number of words included in the series. For example, the 2-gram representation of the first sentence would be as follows:\n",
    "\n",
    "    (She labored), (labored in), (in vain), (vain the), (the rock), (rock would), (would not), (not move).\n",
    "\n",
    "The 3-gram representation of the second sentence would be as follows:\n",
    "\n",
    "    (She was so), (was so vain), (so vain her), (vain her bathroom), (her bathroom mirror), (bathroom mirror was), (mirror was covered), (was covered in), (covered in lip), (in lip prints).\n",
    "\n",
    "Each of the word sets could then operate as its own feature. N-grams can be used to create term-document matrices (though it would now be n-gram-document matrices), or they can be used in topic modeling. In addition, n-grams are useful for text prediction; they can be used to determine what words are most likely to follow in a sentence, phrase, or search query.\n",
    "\n",
    "For a sentence with *X* words, there will be $X-(N-1)$ n-grams. Two-gram phrases are also called *bigrams*, three-gram phrases are called *trigrams*, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use single-word models?\n",
    "\n",
    "Given the benefits of incorporating word context for distinguishing between different meanings of a word, why would any NLP practitioner worth their salt ever use simple word features? Well, models based on single words have several advantages:\n",
    "\n",
    "* N-gram models are considerably more sparse than single-word models. The two `vain` sentences above share four words (`she`, `in`, `vain`, `the`) but zero n-grams. Sparseness does mean that an n-gram model can be stored in a more memory-efficient way. For example, imagine a dict that only lists the n-grams that are present in each sentence, rather than a set of columns with `1` if an n-gram is present and `0` otherwise. But it also means that a larger corpus may be needed to detect any shared patterns across documents. In other words, n-gram models may need more documents before they start to give good results.\n",
    "\n",
    "* Single-word models are straightforward to implement, while models incorporating n-grams are more sensitive to fine distinctions of meaning. Which to choose depends on the goals of the NLP project and the tradeoffs in time and performance for the specific corpus that you are modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of 2-grams\n",
    "\n",
    "Implementing n-grams is quite straightforward using scikit-learn's `CountVectorizer`. The only thing that you need to do is to give a tuple of range as values to `ngram_range` (a parameter of `CountVectorizer`). As the code below demonstrates, you need to provide a value for the parameter `ngram_range=(2,2)` inside `CountVectorizer`. This means that the vectorizer will produce 2-gram features. If you were to give `ngram_range=(1,2)` as the value, then the vectorizer would produce both 1-gram and 2-gram features together. But don't do that just yet—that task will be saved for this checkpoint's assignment.\n",
    "\n",
    "Now, generate your 2-grams and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>29th september</th>\n",
       "      <th>abbreviation living</th>\n",
       "      <th>abdication neighbour</th>\n",
       "      <th>abide consequence</th>\n",
       "      <th>abide figure</th>\n",
       "      <th>ability affection</th>\n",
       "      <th>ability awkwardness</th>\n",
       "      <th>ability difficulty</th>\n",
       "      <th>able attempt</th>\n",
       "      <th>able avail</th>\n",
       "      <th>...</th>\n",
       "      <th>zeal dwell</th>\n",
       "      <th>zeal sport</th>\n",
       "      <th>zeal think</th>\n",
       "      <th>zealand australia</th>\n",
       "      <th>zealous officer</th>\n",
       "      <th>zealous subject</th>\n",
       "      <th>zealously discharge</th>\n",
       "      <th>zigzag go</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   29th september  abbreviation living  abdication neighbour  \\\n",
       "0               0                    0                     0   \n",
       "1               0                    0                     0   \n",
       "2               0                    0                     0   \n",
       "3               0                    0                     0   \n",
       "4               0                    0                     0   \n",
       "\n",
       "   abide consequence  abide figure  ability affection  ability awkwardness  \\\n",
       "0                  0             0                  0                    0   \n",
       "1                  0             0                  0                    0   \n",
       "2                  0             0                  0                    0   \n",
       "3                  0             0                  0                    0   \n",
       "4                  0             0                  0                    0   \n",
       "\n",
       "   ability difficulty  able attempt  able avail  ...  zeal dwell  zeal sport  \\\n",
       "0                   0             0           0  ...           0           0   \n",
       "1                   0             0           0  ...           0           0   \n",
       "2                   0             0           0  ...           0           0   \n",
       "3                   0             0           0  ...           0           0   \n",
       "4                   0             0           0  ...           0           0   \n",
       "\n",
       "   zeal think  zealand australia  zealous officer  zealous subject  \\\n",
       "0           0                  0                0                0   \n",
       "1           0                  0                0                0   \n",
       "2           0                  0                0                0   \n",
       "3           0                  0                0                0   \n",
       "4           0                  0                0                0   \n",
       "\n",
       "   zealously discharge  zigzag go  \\\n",
       "0                    0          0   \n",
       "1                    0          0   \n",
       "2                    0          0   \n",
       "3                    0          0   \n",
       "4                    0          0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 30515 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 2-grams\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, your new features are 2-gram. Next, build the same machine-learning models that you built before for the 1-gram case, but this time, use 2-gram as your features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9165433560224918\n",
      "\n",
      "Test set score: 0.7829560585885486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.76      1.00      0.86      1537\n",
      "     Carroll       0.99      0.32      0.48       716\n",
      "\n",
      "    accuracy                           0.78      2253\n",
      "   macro avg       0.87      0.66      0.67      2253\n",
      "weighted avg       0.83      0.78      0.74      2253\n",
      "\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9529446581828943\n",
      "\n",
      "Test set score: 0.7967154904571683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.78      0.99      0.87      1537\n",
      "     Carroll       0.94      0.38      0.55       716\n",
      "\n",
      "    accuracy                           0.80      2253\n",
      "   macro avg       0.86      0.69      0.71      2253\n",
      "weighted avg       0.83      0.80      0.77      2253\n",
      "\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.7664989641905889\n",
      "\n",
      "Test set score: 0.7616511318242344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.74      1.00      0.85      1537\n",
      "     Carroll       1.00      0.25      0.40       716\n",
      "\n",
      "    accuracy                           0.76      2253\n",
      "   macro avg       0.87      0.62      0.63      2253\n",
      "weighted avg       0.82      0.76      0.71      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "print(classification_report(y_test, lr.predict(X_test)))\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "print(classification_report(y_test, rfc.predict(X_test)))\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))\n",
    "print(classification_report(y_test, gbc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem worse than 1-gram! Even the overfitting in the logistic regression and the random forest is higher than before. That's because in the 2-gram case, you have more features than you have in 1-gram. One possible solution to increase the performance of the models is using 1-gram and 2-gram together as features. This will be one of your tasks in the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completed Assignments \n",
    "\n",
    "*Submit your solutions to the following tasks as a link to your Jupyter Notebook on GitHub.*\n",
    "\n",
    "Your task is to increase the performance of the models that you implemented in the bank-of-words example. Here are some suggested avenues of investigation:\n",
    "\n",
    "* Other modeling techniques and models\n",
    "\n",
    "* Making more features that take advantage of the spaCy information, such as grammar, phrases, parts of speech, and so forth\n",
    "\n",
    "* Making sentence-level features, such as the number of words and amount of punctuation\n",
    "\n",
    "* Including contextual information, such as the length of previous and next sentences, words repeated from one sentence to the next, and so on\n",
    "\n",
    "* Or anything else that your heart desires\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7733057117490382 \n",
      " Test: 0.7101642254771416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.74      0.89      0.81      1537\n",
      "     Carroll       0.58      0.32      0.42       716\n",
      "\n",
      "    accuracy                           0.71      2253\n",
      "   macro avg       0.66      0.61      0.61      2253\n",
      "weighted avg       0.69      0.71      0.68      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN classification model\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "test_score =  knn.score(X_test, y_test)\n",
    "train_score = knn.score(X_train, y_train)\n",
    "print(\"Train: {} \\n Test: {}\".format(train_score, test_score))\n",
    "print(classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.DataFrame({'type': ['k'], 'model': ['knn'], 'test': [test_score], 'train' : [train_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "comp = PCA(n_components=2)\n",
    "pca = pd.DataFrame(data = comp.fit_transform(X_train), columns = ['X', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt \n",
    "#Run the model using highest score values against all records using best k value from sample.\n",
    "kmeanModel = KMeans(n_clusters=5).fit(pca) \n",
    "kClusters = kmeanModel.fit_predict(pca)\n",
    " \n",
    "#add kmeanas clusters to the original dataframe.\n",
    "pca['clusters'] = kClusters\n",
    "\n",
    "pca.plot.scatter(x='X', y='Y', c='clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8005327019828351\n"
     ]
    }
   ],
   "source": [
    "knn.fit(pca, y_train)\n",
    "train_score = knn.score(pca, y_train)\n",
    "print(\"Train: {}\".format(train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6771234092926901\n"
     ]
    }
   ],
   "source": [
    "clusters = pd.get_dummies(pca['clusters'], drop_first=True)\n",
    "knn.fit(clusters, y_train)\n",
    "train_score = knn.score(clusters, y_train)\n",
    "print(\"Train: {}\".format(train_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your models' performances with those of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Performance \n",
    "r = {'type': ['example II', 'example II', 'example II', 'example I', 'example I', 'example I'], \n",
    "       'model': ['logistic','random', 'gradient', 'logistic','random', 'gradient'], \n",
    "       'test': [ 0.7829560585885486, 0.800266311584554, 0.7616511318242344, 0.8761651131824234, 0.8504216600088771, 0.8362183754993342], \n",
    "       'train': [0.9165433560224918, 0.9529446581828943, 0.7664989641905889, 0.9354838709677419, 0.9795797573246523, 0.8514353358981948]}\n",
    "\n",
    "#store the scores in a results table for comparison.\n",
    "results = pd.DataFrame(r)\n",
    "results = results.append(k)\n",
    "results.set_index(['type', 'model'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGfCAYAAAB7g1e6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtGklEQVR4nO3de5hddX3v8feHAAKCoAQ8SMSkHsBSBdSIUtCCLQreqXerVq2ij2jtBY/Q1nqrp55arQflUo7Fa9WjomILCtrDxVYpBBoRUEq8ErGCtCAoAcHv+WOtITvDJNkzaydrVub9eh4estdes/NlM3vm8/t9f+u3UlVIkiRpbrbquwBJkqQhM0xJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB1v39RcvXry4li5d2tdfL0mSNLZLL730J1W120zP9Ramli5dyooVK/r66yVJksaW5Pvre842nyRJUgeGKUmSpA42GqaSnJ7k+iRXrOf5JDkxyaoklyd5xOTLlCRJmp/GWTP1QeB9wIfX8/xRwN7tP48GTmn/LUmSthC/+MUvWL16NWvWrOm7lE1qu+22Y8mSJWyzzTZjf81Gw1RVXZhk6QZOeTrw4WrumHxRkl2S7FFVPxq7CkmSNK+tXr2anXbaiaVLl5Kk73I2iarixhtvZPXq1Sxbtmzsr5vEmqk9gWtHHq9uj0mSpC3EmjVr2HXXXbfYIAWQhF133XXWs2+TCFMzvas144nJMUlWJFlxww03TOCvliRJm8uWHKSmzOW/cRJhajXwwJHHS4DrZjqxqk6rquVVtXy33Wbc90qSJOkebrrpJk4++eQ5fe173vMefv7zn0+4orUmsWnn54HXJPkEzcLzm10vJUnSlm3p8WdN9PW+944nb/D5qTD16le/etav/Z73vIcXvvCF7LDDDnMtb4M2GqaSfBw4DFicZDXwJmAbgKo6FTgbeBKwCvg58NJNUqkkSVqwjj/+eL797W9z4IEHcsQRR7D77rvzyU9+kttvv52jjz6at7zlLfzsZz/jOc95DqtXr+auu+7ijW98Iz/+8Y+57rrrOPzww1m8eDHnnXfexGsb52q+52/k+QKOnVhFkiRJ07zjHe/giiuuYOXKlZx77rl8+tOf5uKLL6aqeNrTnsaFF17IDTfcwAMe8ADOOquZNbv55pvZeeedefe73815553H4sWLN0ltvd2bT5I0D7155wm/3s2TfT0JOPfcczn33HN5+MMfDsCtt97KNddcw2Mf+1iOO+443vCGN/CUpzyFxz72sZulHsOUJEkalKrihBNO4JWvfOU9nrv00ks5++yzOeGEE3jCE57An//5n2/yerw3nyRJmvd22mknbrnlFgCe+MQncvrpp3PrrbcC8MMf/pDrr7+e6667jh122IEXvvCFHHfccVx22WX3+NpNwZkpSZI07+26664ccsghPPShD+Woo47iBS94AQcffDAAO+64Ix/96EdZtWoVr3/969lqq63YZpttOOWUUwA45phjOOqoo9hjjz02yQL0NOvHN7/ly5fXihUrevm7JUnr4Zoprcc3v/lNfvVXf7XvMjaLmf5bk1xaVctnOt82nyRJUgeGKUmSpA5cM6VNw1aBJGmBcGZKkiSpA8OUJElSB4YpSZKkDgxTkiRp3rvppps4+eSTZ/11T3rSk7jpppsmX9AIF6BL2rJ48YO0eWzmz9pUmHr1q1+9zvG77rqLRYsWrffrzj777ImUtyGGKUmSNO8df/zxfPvb3+bAAw9km222Yccdd2SPPfZg5cqVXHXVVTzjGc/g2muvZc2aNbzuda/jmGOOAWDp0qWsWLGCW2+9laOOOopDDz2Ur371q+y5556ceeaZbL/99p1rs80nSZLmvXe84x08+MEPZuXKlbzzne/k4osv5u1vfztXXXUVAKeffjqXXnopK1as4MQTT+TGG2+8x2tcc801HHvssVx55ZXssssunHHGGROpzZkpSZI0OAcddBDLli27+/GJJ57IZz/7WQCuvfZarrnmGnbdddd1vmbZsmUceOCBADzykY/ke9/73kRqMUxJkqTBufe97333n88//3y+/OUv87WvfY0ddtiBww47jDVr1tzja+51r3vd/edFixZx2223TaQWw9T6uIhVkqR5Y6edduKWW26Z8bmbb76Z+973vuywww5861vf4qKLLtqstRmmJEnSvLfrrrtyyCGH8NCHPpTtt9+e+9///nc/d+SRR3Lqqaey//77s++++/KYxzxms9ZmmJIkSbPXQ8flYx/72IzH73Wve/GFL3xhxuem1kUtXryYK6644u7jxx133MTq8mo+SZKkDgxTkiRJHRimJEmSOjBMSZKksVRV3yVscnP5bzRMSZKkjdpuu+248cYbt+hAVVXceOONbLfddrP6Oq/mkyRJG7VkyRJWr17NDTfc0Hcpm9R2223HkiVLZvU1hilJkrRR22yzzTq3b9FahilJvVp6/FkTfb3vzW52XpI6c82UJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sCtESRpwNxaYp55884Tfr2bJ/t62iScmZIkSerAMCVJktSBYUqSJKkD10xJkhYs15xpEpyZkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA7GClNJjkxydZJVSY6f4fmdk/xDkq8nuTLJSydfqiRJ0vyz0TCVZBFwEnAUsB/w/CT7TTvtWOCqqjoAOAx4V5JtJ1yrJEnSvDPOzNRBwKqq+k5V3QF8Anj6tHMK2ClJgB2B/wTunGilkiRJ89A4m3buCVw78ng18Ohp57wP+DxwHbAT8Nyq+uX0F0pyDHAMwF577TWXerWJuHGdJElzM87MVGY4VtMePxFYCTwAOBB4X5L73OOLqk6rquVVtXy33XabZamSJEnzzzhhajXwwJHHS2hmoEa9FPhMNVYB3wUeMpkSJUmS5q9xwtQlwN5JlrWLyp9H09Ib9QPgNwGS3B/YF/jOJAuVJEmajza6Zqqq7kzyGuAcYBFwelVdmeRV7fOnAm8DPpjkGzRtwTdU1U82Yd2SJEnzwjgL0Kmqs4Gzpx07deTP1wFPmGxps+MCakmS1Ad3QJckSepgrJkpSZKkTerNO0/49W6e7OttgDNTkiRJHTgzJc03Ax6dSdJC5MyUJElSB85MSRMwyatJvZJUkobFmSlJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdeCNjiVJ0qxN8gbvMOybvDszJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6mCsMJXkyCRXJ1mV5Pj1nHNYkpVJrkxywWTLlCRJmp+23tgJSRYBJwFHAKuBS5J8vqquGjlnF+Bk4Miq+kGS3TdRvZIkSfPKODNTBwGrquo7VXUH8Ang6dPOeQHwmar6AUBVXT/ZMiVJkuanccLUnsC1I49Xt8dG7QPcN8n5SS5N8uJJFShJkjSfbbTNB2SGYzXD6zwS+E1ge+BrSS6qqn9f54WSY4BjAPbaa6/ZVytJkjTPjDMztRp44MjjJcB1M5zzxar6WVX9BLgQOGD6C1XVaVW1vKqW77bbbnOtWZIkad4YJ0xdAuydZFmSbYHnAZ+fds6ZwGOTbJ1kB+DRwDcnW6okSdL8s9E2X1XdmeQ1wDnAIuD0qroyyava50+tqm8m+SJwOfBL4P1VdcWmLFySJGk+GGfNFFV1NnD2tGOnTnv8TuCdkytNkiRp/nMHdEmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdTBWmEpyZJKrk6xKcvwGzntUkruSPGtyJUqSJM1fGw1TSRYBJwFHAfsBz0+y33rO+1/AOZMuUpIkab4aZ2bqIGBVVX2nqu4APgE8fYbzXgucAVw/wfokSZLmtXHC1J7AtSOPV7fH7pZkT+Bo4NTJlSZJkjT/jROmMsOxmvb4PcAbququDb5QckySFUlW3HDDDWOWKEmSNH9tPcY5q4EHjjxeAlw37ZzlwCeSACwGnpTkzqr63OhJVXUacBrA8uXLpwcySZKkwRknTF0C7J1kGfBD4HnAC0ZPqKplU39O8kHgH6cHKUmSpC3RRsNUVd2Z5DU0V+ktAk6vqiuTvKp93nVSkiRpwRpnZoqqOhs4e9qxGUNUVb2ke1mSJEnD4A7okiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqYKwwleTIJFcnWZXk+Bme/50kl7f/fDXJAZMvVZIkaf7ZaJhKsgg4CTgK2A94fpL9pp32XeA3qmp/4G3AaZMuVJIkaT4aZ2bqIGBVVX2nqu4APgE8ffSEqvpqVf1X+/AiYMlky5QkSZqfxglTewLXjjxe3R5bn98DvtClKEmSpKHYeoxzMsOxmvHE5HCaMHXoep4/BjgGYK+99hqzREmSpPlrnJmp1cADRx4vAa6bflKS/YH3A0+vqhtneqGqOq2qllfV8t12220u9UqSJM0r44SpS4C9kyxLsi3wPODzoyck2Qv4DPCiqvr3yZcpSZI0P220zVdVdyZ5DXAOsAg4vaquTPKq9vlTgT8HdgVOTgJwZ1Ut33RlS5IkzQ/jrJmiqs4Gzp527NSRP78cePlkS5MkSZr/3AFdkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdjBWmkhyZ5Ookq5IcP8PzSXJi+/zlSR4x+VIlSZLmn42GqSSLgJOAo4D9gOcn2W/aaUcBe7f/HAOcMuE6JUmS5qVxZqYOAlZV1Xeq6g7gE8DTp53zdODD1bgI2CXJHhOuVZIkad4ZJ0ztCVw78nh1e2y250iSJG1xth7jnMxwrOZwDkmOoWkDAtya5Oox/v5eBBYDP5nYC75lprdoy+X7N3e+d934/nXj+9eN79/cDeC9e9D6nhgnTK0GHjjyeAlw3RzOoapOA04b4+/sXZIVVbW87zqGyvdv7nzvuvH968b3rxvfv7kb8ns3TpvvEmDvJMuSbAs8D/j8tHM+D7y4varvMcDNVfWjCdcqSZI072x0Zqqq7kzyGuAcYBFwelVdmeRV7fOnAmcDTwJWAT8HXrrpSpYkSZo/xmnzUVVn0wSm0WOnjvy5gGMnW1rvBtGOnMd8/+bO964b379ufP+68f2bu8G+d2lykCRJkubC28lIkiR1YJiSJEnqYKw1UwtBkuXAY4EHALcBVwBfrqr/7LWwgfD96ybJfVn73n2vqn7Zc0mDkGQ74Cnc83vvrKq6ss/atDAk2Qo4gLXff1dW1Y/7rWo4kuwOHMK6n98VQ/sZuODXTCV5CfD7wHeBS4Hrge2AfWj+B18BvLGqftBXjfOZ79/cJdmZ5sKN5wPbAjfQvHf3By4CTq6q8/qrcH5L8mbgqcD53PN77/D2z39cVZf3VOK8ZxiduyQPBt4A/BZwDWs/v/vQXNX+t8CHhhYKNpckhwPHA/cD/o11P78PBj4NvKuqftpbkbPgzBTcGzikqm6b6ckkB9LcwNkwMDPfv7n7NPBh4LFVddPoE+1M3wuT/EpV/V0fxQ3AJVX15vU89+52xLvXZqxnUKaF0X9l3V9m72iDlmF0/f4COAV4ZU2blWi/914AvAj4UA+1DcGTgFfMNNBOsjVNyD8COGNzFzYXC35mSpIWoiRPrqqzNvD87sBeVbViM5Y1OEnuVVW3b+yYtmyGqVaSDwGvm5ohaNewvKuqXtZrYQORZBnwWmApIzOeVfW0vmoaiiT/VFW/ubFjmlmSLwHPnvbZ/URVPbHXwrQgJLmsqh6xsWOaWZJ7Ac/knr873tpXTXNhm2+t/UdbLVX1X0ke3mM9Q/M54O+AfwBcIzCGto2yA7C4DQBTd+W8D836FY1n8Qyf3d17rGdQ2pbyn9LcxHVrmu/Dqqr9ey1snkvy34A9ge3b3xWjn98deitseM4EbqZZ9zjY2TzD1FpbJblvVf0XQJL74fszG2uq6sS+ixiYVwJ/QBOcLmXtD+OfAif1VNMQ/TLJXlNrL5I8CHDKfXx/D7we+AYOhGbjicBLgCXAu0eO3wL8SR8FDdSSqjqy7yK6ss3XSvJi4ASaRcEAzwbeXlUf6a+q4UjyApqF5ucyMrqoqst6K2ogkry2qt7bdx1DleRImttQXNAeehxwTFWd019Vw5Hkn6vq0L7rGKokz6yqQSySno+SnAa8t6q+0XctXRimRiTZD3g8zQzBP1XVVT2XNBhJ/pLmypVvs3Z0W1X1+P6qGo4kv8491wx8uLeCBibJYuAxNJ/dr1XVT3ouaTCS/CbN9hz/xLoDoc/0VtSAbClrfvqS5Crgv9Nsr3M7A20zL/gwleQ+VfXTtq13D246OZ4k36JZd3ZH37UMTZKP0OyrshK4qz1cVfX7vRU1AEkeUlXfSjLjQl9nRceT5KPAQ4ArWXcg5MU3Y0jyRdau+Zn6/FJV7+qtqAFp2/L3UFXf39y1dOGaIPgYzX4Wl7LuOou0j3+lj6IG6OvALjR71Wh2lgP7Td+rRhv1R8AxwEy/tIpmllkbd0BVPazvIgZsi1jz05eq+n6SRTSbFQ82kwy28Empqqe0/17Wdy0Dd3/gW0kuYd1WgVsjbNwVwH8DftR3IUNSVce0fzyqqtaMPtdeKanxXJRkP5c1zNlXkzxs6Gt++pLktcCbgB8zMjMK2OYbIvf66SbJb8x0vKoumOm41kpyHnAgcDEG0Vlzn59uknyTps086DUrfdlS1vz0Jckq4NFVdWPftXSx4Gem3OtnMqrqgiT3Bx7VHrq4qmz5jefNfRcwRO7zMzG2qLo5qu8CBu5amjVng7bgwxTu9TMRSZ4DvJPmPl8B3pvk9VX16Q1+oaaC6IOAvavqy0l2ABb1XdcAjO7z8y7Wfnbd52cW2jUrB9Dc7BjgK1X19T5rGpL2/TuU5vP7gSS7ATv2XdeAfAc4P8lZrDsz/+71f8n8Y5uv5V4/3ST5OnDE1GxU+wPly1V1QL+VzX9JXkGzkPp+VfXgJHsDp9piHo/7/HST5HXAK4CprRCOBk7z5+F4kryJ5iKSfatqnyQPAD5VVYf0XNogtO/fdDW0rSWcmVrrP5LsVFW3JPkz4BHAX3h59di2mtbWuxHYqq9iBuZY4CDgXwGq6hpvhzIrS5Lch2ZG6v/QfHaPr6pz+y1rMH6PZs3KzwCS/C/ga4BhajxHAw8HLgOoquuS7NRvSYPyoar63uiBJI9az7nzlr/s1npjG6QOpWkffAg4peeahuSLSc5J8pIkLwHOAs7uuaahuH10f64kW+PtUGbjZVX1U+AJwO7AS4F39FvSoISR/ZHaP2c95+qe7mi3NSmAJPfuuZ6hOSPJnlMPkjwOOL3HeubEmam1pn6YPBk4parOTPLmHusZlKp6fZJnAofQ/CA+rao+23NZQ3FBkj+hWUh9BPBqmhtGazxTv/ifBHygqr6exDAwvg8A/5pk6vP6DJqblms8n0zyt8Aubcv+ZTQzpBrPq4DPJXkqzazy/6T5LA+Ka6ZaSf4R+CHwW8AjgdtorkhzzY82qSRb0bRankATDM4B3u8mnuNJ8gGaq/qWAQfQLN4/v6oe2WthA9LuIn8ozfffhVX1bz2XNCjtIOjuz29VfannkgYlycHA3wJrgCdX1Q09lzRrhqlWewXVkcA32jUrewAPc93FhiW5hQ20pKrqPpuxHC1AbRg9EPhOVd2UZFdgz6q6vN/K5rf13UJrirfS0qaU5B9Y93fHfjQbF/8XDG+fvQXf5pu6Nx+wHc1l/VM/ZG4HVvRY2iBU1U4ASd4K/AfwEZrR2e8ALsLcgCSfrKrnJPkGMwRSN/3bsKl789EEKYBfsbs3K1O30AqwF80vsdDcFuoHNDN9Wo8k/1xVh84woJzatNOB5Ib9dd8FTNKCn5lK8o9V9ZQk32XtD5YpVVXem28MSf61qh69sWNaK8keVfWjLeVGn5tbktOq6ph2B/npqqq8N98YkpwKfL6qzm4fHwX8VlX9cb+VScOx4MOUJiPJV2k2Of0ETSh9PnBsVf16r4VJ2qAkl05fX5ZkRVUt76umIbBNqlELvs03pV2AOd3NwPer6s7NXc8AvQD43+0/BfxLe0zr4XqzyUjy2zMcvplm/aO3NNq4n7R7632U5vvxhTT7xGnDbJPqbs5MtZJcRHNZ5uU0H4iHAV8HdgVe5UJ0bSrrW29WVX/Va2ED0d6G4mBgqt13GHARsA/w1qr6SE+lDUI7w/Im4HHtoQuBtzizMh7bpALD1N2SfAJ4W1Vd2T7eD3g98DbgM1V1YI/lzXvt7WNeASxlZMazql7WV01D4Xqzbtqrgl5eVT9uH9+fZsPdl9Nc5v/QPuvTls026WQl+RDwc+Ckqrqi73rGZZtvrYdMBSmAqroqycOr6jteITSWM4GvAF9m3d2UtXF3Jfkd1l1v5ns4vqVTQap1PbBPVf1nkl/0VdRQJNkHOI57DoRcwD8e26ST9T6atumLgDf0XMvYDFNrXZ3kFJpfaADPBf49yb0AfyBv3A5VNZhv/HnG9WbdfKXddPdT7eNnARe2t/W4qbeqhuNTwKnA+zHEz8XzadqkUzvIX9ge0xiSLB29N19VXZKEod283DZfK8n2NLfxmNoF+J+Bk2l2ZN2hqm7tsbx5L8lfAF+dWjcgbS7trWN+m3U/u2e4g/x4ZmpTSZtLksuAp1bVD9vHvwG8r6oe1m9ls2OYGpFkW2BfmtmBq6vKGakxtVem3Ztms9Nf4MZ1Y0uyHc3tZH6NZvNYwPVms9GukzqI5rN7sVfxja+9B+n1NDMrt08ddwH6eNr1ov+De35+bZOOIcmjaCYuRu/N99SqurbXwmbJMNVKchjwIeB7NEHggcDvVtWF/VWlhSDJp4Bv0bT23kpzNd83q+p1vRY2EEmeA7yT5g4GAR4LvL6qPt1nXUPRblg8nRsWjynJucD/pVl39irgd4EbXPYwPu/NtwVJcinwgqq6un28D/Bxp7/Hl+S+wN6sOzozjG5Ekn+rqocnubyq9k+yDc3NUh3ZjiHJ14Ejpmaj2pmCL3uTcm0OU23Sqc9ve+yCqvqNvmubz7w335Zrm6kgBVBV/97+UtMYkrwceB2wBFgJPAb4GmAg2LipdvJNSR5Ks+fU0v7KGZytprX1bgS26quYIWq/7/Zj3YHQh/uraFCmPr8/SvJk4Dqan4PasC3q3nyGqbVWJPk7mo0ToWm1XNpjPUPzOuBRwEVVdXiShwBv6bmmoTitndX7M+DzwI7AG/staVC+mOQc4OPt4+cCXggxpiRvotnodD+a9+0omkX8hqnx/EWSnYE/Bt4L3Af4w35LGoQLN3aRSJIM5UIS23ytdguEY1l7RdCFwMlVdfsGv1AAJLmkqh6VZCXw6Kq6PclKNzvdsCRbAc+qqk/2XcuQJXkmcAjtZ7eqPruRL1EryTeAA4B/q6oD2sX876+qp/Zc2ryXZBHw+1X1N33XMjRJzgfOAM6sqh+MHN+W5vfw7wLnVdUHeylwlgxTmogknwVeCvwBTWvvv2hap0/qs64hSHJhVT1u42dKk5fk4qo6qF03ejhwC3BFVf1az6UNQpLzqurwvusYmvYq5pfRdIGW0ewJtx2wCDiXZgf0lX3VN1sLPky1o7IN3Wx2/81Yzhah3SdkZ+CLVXVH3/XMd0neCNxGc0XQz6aOe2n6hm3gRtFuyzELSU4G/gR4Hk2r6lZgZVW9tNfCBiLJ22l+3k3//F7WW1ED065PXgzcVlU39VzOnBimkgdt6Pmq+v7mqmWo2lbV5d4DbW68NF19aTc8XTK1p0+SpcB9quryXgsbkCTnzXC4vBp3YVnwYUqTkeTvgRNGe9+S5j93QJe682o+TcoewJVJLmbdqe5B7RXShyS/PcPhm4FvuJO3NoOLkjyqqi7pu5AhSvJHMxy+Gbh0SGt+1I0zU5qIdp3UPVTVBZu7lqFJchZwMDDVLjgMuAjYB3hrVX1kPV8qdZbkKprvte/TDISm1py5XnQMST4GLAf+oT30ZOAS4CHAp6rqr/qqTZuPYUrqWbsT8Mur6sft4/sDpwAvp7nM37Vo2mTWt27U9aLjafc4e2ZV3do+3hH4NHA0zezUfn3Wp83DNt96JPkQ8HOayzOv6LsebdGWTgWp1vXAPlX1n0m82fYsJfkyza7UJ1XVP/Zdz3xnaOpsL2D0quVfAA+qqtuSuE/hAmGYWr/30XxIXgR4w0ptSl9J8o/Ap9rHzwQuTHJvmr1XNDsvplnD95i+C9GC8DGadWdnto+fCny8/fxe1V9Z2pxs80k9ay9P/23W7r7/z8AZQ7mNgrTQJXkkI5/fqlrRc0nazBZ8mJrhztXr8Gq0ubFNqk1tAxvuuoBa0mZlmFrPVWhTvBptbpI8iqZNelBV2SbVxLnh7qbhmjNp9hZ8mJIkrZXkAbRrzqrqpL7rkYZgwYcp783XjW1SSdJC59V88JS+Cxi4v+67gC2N6820ObjmbNOwTbowLfiZKWm+cb3Z7CXZHtirqq7uu5ahcM3ZpmGbdGEyTKkT26TqW5Kn0syQbltVy5IcSHMbHlvMkjYLw5Q6cXQ7d643m4wklwKPB86vqoe3xy43yGtTsk2qUa6ZGmGrYPYMS5243mwy7qyqm5u9T6XNxvW2upthqjXaKgBsFWiTcw+zibkiyQuARUn2Bn4f+GrPNQ2KA8nZcyCpUbb5WrYKtLm53mwykuwA/CnwBJoWyznA26pqTa+FDYRrzqTunJlay1ZBR45uZ802wQRU1c9pwtSf9l3LQL0ZOAg4H6CqViZZ2mM90uAYptayVdCBbdLZs03QjQv4J8aBZEcOJGWYWuu1NCPb24GP07YKeq1oWN6Mo1ttXi7gnwwHkh04kBS4ZkoTkuRfq+rRSf7NNWfa3JJsCzyEZqbq6qq6o+eSBsM1Z9243lbgzJStgslxdNuBbYK5S/Jk4FTg2zRhYFmSV1bVF/qtbBhcc9aZbVIZprBVMCm2SefINkFn7wIOr6pVAEkeDJwFGKY2wIHkxDiQlG2+UbYK1AfbBN0kubCqHjfyOMAFo8d0T0l+Y0PPuw/aeGyTCgxTd5upVQDYKtgIR7fdud6smySnAA8CPknzvfhs4GrgXwCq6jP9VTcMDiSlbmzzrWWrYG5sk3Znm6Cb7YAfA1MzLTcA9wOeShMODFMb4JqzuXEgqVHOTLVsFXTn6HZubBOoT0m+BTxl+kCyqh7Sb2Xzm21SjTJMtWwVdGObVH1JsozmAoiljMy2OzMwHgeS3TmQlGGqleQDG3i6quplm62YAXJ0O3u2CSYjydeBvwO+Afxy6rgzA+NxINmNA0mBYUoT4uh29mwTTMbUAv6+6xgqB5LdOJAUGKbuZqugG0e33dgmmLt28f7ewLk0+5wBUFWX9VaUFgwHkgLD1N1sFXTj6HbubBN0k+QvgRfRvH9Tn92qqsf3V9VwOJDsxoGkwDB1N1sF6ottgm7a929/Z/PmxoFkNw4kBe4zNep/J3kTtgrmxNFtJ9dPBanWd4Dr+ypmgL4O7ILv2VytqaoT+y5iqKrqpX3XoP45M9WyVdCNo9u5s03QTZLzgf2BS1h3IGSQH4NrzrpxICkwTN3NVkE3tknnzjZBN+u7KtIgPx4Hkt04kBQYpu6W5P8Cr60qWwVz4OhWGiYHkt04kBS4ZmrU/YFvJbFVMDcPoxndPp6R0W37WBtgm6CbJI8B3gv8KrAtsAj4WVXdp9fChsM1Z9243laGqRFv6ruAgTsa+BVHt3PyOZo2wT8w0ibQ2N4HPA/4FLAceDHNLKnG40CyGweSMkxNsb/dmaPbufNqqo6qalWSRVV1F/CBJF/tu6YBcSDZjQNJGaam2CrozNHt3Nkm6Obn7Q7yK5P8FfAj4N491zQYDiQ7cyApw9QIWwXdOLqdO9sE3bwI2Ap4DfCHwAOBZ/Za0YA4kOzMgaQMU6NsFcydo9tObBN0c1tVrQHWAG8BSLJvvyUNigPJbhxIyjA1wlZBB45uO7FN0M1Xkryxqj4JkOSPgd8D9uu3rOFwIDl3DiQFhqlRtgq6cXQ7d7YJujkMOC3Js2ney28CB/Va0bA4kOzAgaTAMDXKVkFHjm7nzDZBB1X1oyRfBE6gWXN2QlXd2nNZQ+JAshsHkjJMjbBV0I2j2zmyTdBNki/RfL89FFgCnJ7kwqo6rt/KBsOBZEcOJLVV3wXMI4cBL0ryqSQXAvtgq2A2Rke3P8PR7diSPCbJJUluTXJHkruS/LTvugbkpKp6cVXdVFVXAAcDN/dd1IB8Jclzph60A8nP9ljP0KwzkEzyhziQXHC8N9+IJMeytlXw/Kr6l55LGowku0+/r2GSfavq6r5qGookK5ihTVBVf9JrYQOS5FCa9+wDSRYDO1XVd/uuawiS7AGcRjMzNbXm7I9tlY4nyYOAH9Osl/pDYGfg5Kpa1Wth2qycmWq1rYJH07QKngT8TZK/7reqQXF020H7g3dRVd1VVR+gmSnVGNoNT99AMxCC5pfaR/uraFiq6kfAF2lm9JYCHzZIzcptVbWmqn5aVW+pqj+iWYSuBcQwtZatgm4OwzbpXNkm6OZo4Gk07WWq6jpgp14rGhAHkp05kJRhakpVfS7JoUle2h66L45ux+bothPXm3VzRzXrFQogiUF0dhxIdnMYDiQXPMNUy1ZBN45uO7FN0M0nk/wtsEuSVwBfBv5PzzUNhgPJbhxICgxTo2wVdOPodu5sE3RQVX8NfBo4A9gX+POqem+/VQ2HA8luHEgK3Gdq1B1VVUlsFczB1OiW9ooqHN3OxmG4g/esJUnb3qOqvgR8aUPnaL2OBh4OXAbNQDKJA8nxnVRVn2v/fFOSgwGvxF1gnJlay1ZBB45u5842wZydl+S1SfYaPZhk2ySPT/Ih4Hd7qm1IXHPWgW1SgTNTd6uqv05yBPBT1rYK7jHS1Xo5up0jd/CesyOBlwEfT7IMuAnYnmaQeC7wN1W1srfqhmP6QPJlOJAcWzuQXE7ze+MDrB1IHtJnXdq8FvymneO0AWwVbFySi6vqoCSXVdUj2tHt16pq/75rm++SPGOkTUCSRcCfVNXb+qtqWJJsAyymWcx/U8/lDE47kHwCEOAcB5LjS7KSdiBZVQ9vj13uz76FxZmpplVwBnBmVf1g6mC778+hNG2C84AP9lPeYDi6nSPXm3VXVb+gmd3TmFxzNjGut5UzU0m2o/nF/zvATK2Ck2wVjMfR7dyMtgmqap8kDwA+VVW2CbTJJDmf5grIDQ4kq+qDvRQ4EEmOA/YGjgD+kub3yce8onRhWfBhapStgtmzTdqdbQL1wYHk5DiQlGFKnTi67c71ZuqbA8nZcyCpUW6NoK6OBO6iuaLquiRXJfkucA3wfJorqj7YZ4ED4LYc6lVV/aKqfmSQmhW35tDdnJnSxDi6nTvbBNKw2CbVKMOU1BPbBNKWwYGkbPNJ/bFNIG0BbJPKmSmpJ7YJJGnLYJiS5gHbBJI0XIYpSZKkDlwzJUmS1IFhSpIkqQPDlKRNKskuSV7ddx3jSvLBJM/qeo6khcMwJWlT2wUYTJiSpNkyTEna1N4BPDjJyiSfSvL0qSeS/H2SpyV5SZIzk3wxydVJ3jRyzguTXNx+/d8mWTT9L0jyvST/M8nXkqxI8ogk5yT5dpJXteckyTuTXJHkG0meO3L8fe2tkM4Cdh953UcmuSDJpe3r7bEp3yhJw2SYkrSpHQ98u6oOBN4HvBQgyc7ArwNnt+cdRLPn1oHAs5MsT/KrwHOBQ9qvv6s9ZybXVtXBwFeADwLPAh4DvLV9/rfb1z4A+C3gnW04OhrYF3gY8Iq2pqntKt4LPKuqHgmcDry9yxshacu0dd8FSFo4quqCJCcl2Z0m3JxRVXcmAfhSVd0IkOQzwKHAncAjgUvac7YHrl/Py3++/fc3gB2r6hbgliRrkuzSvt7Hq+ou4MdJLgAeBTxu5Ph1Sf5f+zr7Ag8FvtT+3YuAH03orZC0BTFMSdrcPkIzu/Q8mh3gp0zf9K5obvz8oao6YYzXvb399y9H/jz1eOv2tdZnpg33AlzZznZJ0nrZ5pO0qd0C7DTy+IPAHwBU1ZUjx49Icr8k2wPPAP4F+CfgWe1MFu3zD2r//OEkB82ijguB5yZZlGQ3mhmpi9vjz2uP7wEc3p5/NbBbkoPbv2+bJL82i79P0gLhzJSkTaqqbkzyL0muAL5QVa9P8k3gc9NO/WeaWav/DnysqlYAJPkz4NwkWwG/AI4Fvg/sz+zabp8FDga+TjMT9T+q6j+SfBZ4PE178N+BC9q672i3PzixXd+1NfAe4MoZXlvSAubtZCRtVkl2oAkuj6iqm9tjLwGWV9VrxnyN+wB/V1XP3mSFStKYbPNJ2myS/BbwLeC9U0FqLqrqpwYpSfOFM1OSJEkdODMlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOvj/kP7PlMvNPJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot.bar(figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II\n",
    "In the 2-gram example above, you only used 2-gram as your features. \n",
    "\n",
    "This time, use both 1-gram and 2-gram features together as your feature set. \n",
    "\n",
    "Run the same models as in the example and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>29th september</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abbreviation living</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abdication neighbour</th>\n",
       "      <th>abide</th>\n",
       "      <th>abide consequence</th>\n",
       "      <th>abide figure</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand australia</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealous officer</th>\n",
       "      <th>zealous subject</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zealously discharge</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzag go</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  29th september  abbreviation  abbreviation living  abdication  \\\n",
       "0    0     0               0             0                    0           0   \n",
       "1    0     0               0             0                    0           0   \n",
       "2    0     0               0             0                    0           0   \n",
       "3    0     0               0             0                    0           0   \n",
       "4    0     0               0             0                    0           0   \n",
       "\n",
       "   abdication neighbour  abide  abide consequence  abide figure  ...  \\\n",
       "0                     0      0                  0             0  ...   \n",
       "1                     0      0                  0             0  ...   \n",
       "2                     0      0                  0             0  ...   \n",
       "3                     0      0                  0             0  ...   \n",
       "4                     0      0                  0             0  ...   \n",
       "\n",
       "   zealand australia  zealous  zealous officer  zealous subject  zealously  \\\n",
       "0                  0        0                0                0          0   \n",
       "1                  0        0                0                0          0   \n",
       "2                  0        0                0                0          0   \n",
       "3                  0        0                0                0          0   \n",
       "4                  0        0                0                0          0   \n",
       "\n",
       "   zealously discharge  zigzag  zigzag go  \\\n",
       "0                    0       0          0   \n",
       "1                    0       0          0   \n",
       "2                    0       0          0   \n",
       "3                    0       0          0   \n",
       "4                    0       0          0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 35386 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use 2-grams\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# We split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.87      0.97      0.91      1537\n",
      "     Carroll       0.91      0.68      0.78       716\n",
      "\n",
      "    accuracy                           0.88      2253\n",
      "   macro avg       0.89      0.82      0.84      2253\n",
      "weighted avg       0.88      0.88      0.87      2253\n",
      "\n",
      "----------------------Random Forest Scores----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.87      0.93      0.90      1537\n",
      "     Carroll       0.83      0.71      0.76       716\n",
      "\n",
      "    accuracy                           0.86      2253\n",
      "   macro avg       0.85      0.82      0.83      2253\n",
      "weighted avg       0.86      0.86      0.86      2253\n",
      "\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.82      0.97      0.89      1537\n",
      "     Carroll       0.90      0.53      0.67       716\n",
      "\n",
      "    accuracy                           0.83      2253\n",
      "   macro avg       0.86      0.75      0.78      2253\n",
      "weighted avg       0.84      0.83      0.82      2253\n",
      "\n",
      "----------------------KNN Boosting Scores----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Austen       0.79      0.83      0.81      1537\n",
      "     Carroll       0.59      0.51      0.55       716\n",
      "\n",
      "    accuracy                           0.73      2253\n",
      "   macro avg       0.69      0.67      0.68      2253\n",
      "weighted avg       0.72      0.73      0.73      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Reports\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print(classification_report(y_test, lr.predict(X_test)))\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print(classification_report(y_test, rfc.predict(X_test)))\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print(classification_report(y_test, gbc.predict(X_test)))\n",
    "print(\"----------------------KNN Boosting Scores----------------------\")\n",
    "print(classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results Table\n",
    "t = []\n",
    "#type indicator for the results dictionary\n",
    "for i in range(0, 4):\n",
    "    t.append('two')\n",
    "#dictionary for these results.\n",
    "d = {'type': t}\n",
    "\n",
    "\n",
    "d['model'] = ['logistic']\n",
    "d['test'] = [lr.score(X_test, y_test)]\n",
    "d['train'] = [lr.score(X_train, y_train)]\n",
    "\n",
    "\n",
    "d['model'].append('random')\n",
    "d['test'].append(rfc.score(X_test, y_test))\n",
    "d['train'].append(rfc.score(X_train, y_train) )\n",
    "\n",
    "d['model'].append('gradient')\n",
    "d['test'].append(gbc.score(X_test, y_test))\n",
    "d['train'].append(gbc.score(X_train, y_train) )\n",
    "\n",
    "d['model'].append('knn')\n",
    "d['test'].append(knn.score(X_test, y_test))\n",
    "d['train'].append(knn.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">two</th>\n",
       "      <th>logistic</th>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.955608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.860186</td>\n",
       "      <td>0.979580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient</th>\n",
       "      <td>0.833555</td>\n",
       "      <td>0.849068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.730581</td>\n",
       "      <td>0.809707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   test     train\n",
       "type model                       \n",
       "two  logistic  0.875277  0.955608\n",
       "     random    0.860186  0.979580\n",
       "     gradient  0.833555  0.849068\n",
       "     knn       0.730581  0.809707"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(d)\n",
    "d.set_index(['type', 'model'], inplace=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = pd.concat([results, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_results.plot.bar(figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, hands down, takes the cake on this classification example. While not noted - is was observed over several processes (I've run this notebook several times because I'm prone to logistical errors), anyway - it has a pretty fast fit and score time. The model I selected, KNN - has the longest runtime.\n",
    "\n",
    "The Random forest model gets better scoring results. It has the highest testing scores. When it comes to which example to use - I'd go with the number two example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
